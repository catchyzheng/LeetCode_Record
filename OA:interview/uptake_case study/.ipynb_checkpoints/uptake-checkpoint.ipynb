{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core import debugger as pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before read csv 1541798707.19\n",
      "after read csv 1541798715.87\n",
      "col 481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"for attri in df.columns:\\n    if df[attri].dtype == 'object':\\n        df[attri] = df[attri].astype('category')\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import *\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "print 'before read csv', time.time()\n",
    "_df = pd.read_csv('data/train.csv')\n",
    "\n",
    "print 'after read csv', time.time()\n",
    "#print df.dtypes\n",
    "#col_count = open('col_count.txt', 'w+')\n",
    "#row_count = open('row_count.txt', 'w+')\n",
    "col_null = _df.shape[0] - _df.count() #显示每列的空null个数\n",
    "#print >> row_count, df.shape[1] - df.count(axis=1) #显示每行的空null个数\n",
    "for i in range(len(_df.columns)):\n",
    "    print _df.shape[0], 2 * col_null[i]\n",
    "    if _df.shape[0] < 2*col_null[i]:\n",
    "        _df.dropna(subset=[_df.columns[i]], inplace = True)\n",
    "        \n",
    "print 'col', _df.shape[1]\n",
    "\n",
    "#filtered df\n",
    "#df = DataFrame() \n",
    "#col_cnt = open('col_count_v2.txt', 'w+')\n",
    "'''for i in range(len(_df.columns)):\n",
    "    if _df.shape[0] >= 2*col_null[i]:\n",
    "        if _df[_df.columns[i]].dtype == object:\n",
    "            dic = defaultdict(int)\n",
    "            dic2 = defaultdict(int)\n",
    "            cnt = 1\n",
    "            for k in range(1, len(_df[_df.columns[i]])):\n",
    "                if _df[_df.columns[i]][k] is not np.nan:\n",
    "                    dic[_df[_df.columns[i]][k]] += 1\n",
    "                    if dic[_df[_df.columns[i]][k]] == 1:\n",
    "                        dic2[_df[_df.columns[i]][k]] = cnt; cnt += 1\n",
    "                else:\n",
    "                    dic[''] += 1\n",
    "            \n",
    "            max_val = 0; max_key = ''\n",
    "            for key in dic:\n",
    "                if max_val < dic[key]:\n",
    "                    max_val = dic[key]; max_key = key\n",
    "            \n",
    "            print 'why??'\n",
    "            data2 = _df[[_df.columns[i]]]\n",
    "            data2 = fill_missing_numeric(data2, _df.columns[i], dic2, max_key)\n",
    "            df[_df.columns[i]] = data2[_df.columns[i]]\n",
    "            \n",
    "        else: \n",
    "            df[[_df.columns[i]]] = _df[[_df.columns[i]]]\n",
    "            #del df[[df.columns[i]]]\n",
    "    else:\n",
    "        pass #print df.columns[i]'''\n",
    "\n",
    "\n",
    "\n",
    "'''new_data = open('data_type.txt', 'w+')\n",
    "for ele in df.columns:\n",
    "    print >> new_data, ele, type(ele)'''\n",
    "\n",
    "'''for attri in df.columns:\n",
    "    if df[attri].dtype == 'object':\n",
    "        df[attri] = df[attri].astype('category')'''\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481\n"
     ]
    }
   ],
   "source": [
    "df_drop = _df.dropna(axis=1, thresh=_df.shape[0]//2)\n",
    "df_drop_all = df_drop.dropna(axis=0, how='any')\n",
    "\n",
    "print df_drop_all.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "m = df.shape[0] # row\n",
    "n = df.shape[1] # col\n",
    "print 'row:', m, 'col:', n\n",
    "\n",
    "for attri in df.columns:\n",
    "    if df[attri].dtype == object:\n",
    "        print 'encode'\n",
    "        class_le = LabelEncoder()   \n",
    "        df[attri] = class_le.fit_transform(df[attri].values)\n",
    "    else:\n",
    "        print 'numerical'\n",
    "        for i in range(len(df[attri])):\n",
    "            if np.isnan(df[attri][i]):\n",
    "                #data2[attri][i] = round(data2.median()[attri], 3)\n",
    "                df[attri][i] = df.median()[attri]\n",
    "\n",
    "    \n",
    "'''#print 'new', new_df.dtypes\n",
    "for attri in df.columns:\n",
    "    if df[attri].dtype == 'category':\n",
    "        #print '6666666666'\n",
    "        #df[attri] = df[attri].astype('category')\n",
    "        imputer = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis = 0, copy = True)\n",
    "        imputer = imputer.fit(df[[attri]])\n",
    "        df[[attri]] = imputer.transform(df[[attri]])\n",
    "    else:\n",
    "        imputer = Imputer(missing_values = 'NaN', strategy = 'median', axis = 0, copy = True)\n",
    "        imputer = imputer.fit(df[[attri]])\n",
    "        df[[attri]] = imputer.transform(df[[attri]])'''\n",
    "        \n",
    "new_col_count = open('new_col_count.txt', 'w+')\n",
    "#row_count = open('row_count.txt', 'w+')\n",
    "new_null_cnt = df.shape[0] - df.count() #显示每列的空null个数\n",
    "for i in range(len(df.columns)):\n",
    "    print >> new_col_count, df.columns[i], new_null_cnt[i]\n",
    "\n",
    "\n",
    "\n",
    "print 'after statistic', time.time()\n",
    "\n",
    "#显示每列有多少种类型的值，每种出现多少次\n",
    "'''value_cnt = open('value_cnt.txt', 'w+')\n",
    "for lei in df.columns:\n",
    "    print >> value_cnt, df[lei].value_counts()'''\n",
    "\n",
    "\n",
    "train_data = df[:m-1]\n",
    "train_label = df[m-1:m]\n",
    "print train_data.shape[0], train_data.shape[1]\n",
    "print train_label.shape[0]\n",
    "\n",
    "#clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'fuck!!!'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
