print('Hello world - Python!')

kaiqi zheng

data1, data2

L3 = 0
for i in range(l):
    L3 += (data1[i] - data2[i])*(data1[i] - data2[i])*(data1[i] - data2[i])

L3 = cube_root(L3)


X = 1000 data points

# k in [50, ...]:
k = 50
while i < 10:
    traingset = 900 points, testingset = 100 points
    
    for point in testingset:
        find k smallest distances among 900 comparison.
        find the voting of labels in K samples. 
        return Q as predicted label.
    
    compare each point predicting label to true label, calculate the accuracy. 


##################################
Input:
Billions of training examples in a file. Each example has one of 4 class labels
Output:
Select Mc random samples from each class c={1, ..., 4}
##################################

every line:

c1 ... ... ... ...

c1: 100
c2: 200
c3: 300
c4: 400

seen c1 sample : 100+x
for the new c1 sample:
the p1 = 1/(100+x)
for existing 100 sample:

100/(100+x) * 1/100

count = 0
res = []
for line in dataset:
    if line is c1:
        if count < 100:
            res.append(line)
        elif count >= 100:
            if rand() < 100/count:
                choose line into res
                select one sample from res with 1/100 and throw it.
            else:
                drop this line
        count += 1
    else: continue
return res

